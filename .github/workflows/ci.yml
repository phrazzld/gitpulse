name: CI

on:
  push:
    branches: [master, main]
  pull_request:
    branches: [master, main]

# Set required permissions
permissions:
  contents: read
  pull-requests: write
  checks: write

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate dependency compatibility
      run: node scripts/validate-dependencies.js
      # Ensures build fails if incompatible dependency versions are detected
      
    - name: Run enhanced security audit
      # This ensures the build fails if any high or critical severity vulnerabilities are found in production dependencies
      # See our Development Philosophy: CI builds MUST FAIL on discovery of critical/high severity vulnerabilities
      run: |
        # Install required dependencies for the security-auditor script
        cd scripts/security-auditor
        npm install
        cd ../..
        # Run the enhanced security audit
        npm run audit:security
      
    - name: Lint
      run: npm run lint
      # Ensure the build fails if linting fails
      
    - name: Type check
      run: npm run typecheck
      # Ensure the build fails if type checking fails
      
    - name: Build
      run: npm run build
      # Ensure the build fails if the app build fails
      
    - name: Build Storybook
      run: npm run build-storybook
      # Ensure the build fails if Storybook build fails
      
    - name: Run Tests with Coverage
      run: npm run test:ci
      env:
        GEMINI_API_KEY: 'test-api-key-for-testing-only'
      # This step will fail if:
      # 1. Any tests fail
      # 2. Coverage thresholds are not met (configured in jest.config.js)
      # Coverage thresholds: Global ≥ 80%, Atoms ≥ 90%, Molecules ≥ 85%, Organisms ≥ 80%
    
    - name: Read Coverage Summary
      id: read-coverage
      if: github.event_name == 'pull_request'
      run: |
        # Fix malformed coverage JSON and extract coverage percentages safely using jq
        if [[ -f "coverage/coverage-summary.json" ]]; then
          echo "🔧 Fixing malformed coverage JSON format..."
          node scripts/fix-coverage-json-simple.js
          
          if [[ -f "coverage/coverage-summary-fixed.json" ]]; then
            echo "✅ Using fixed coverage JSON"
            COVERAGE_FILE="coverage/coverage-summary-fixed.json"
          else
            echo "⚠️ Fix failed, attempting to use original file"
            COVERAGE_FILE="coverage/coverage-summary.json"
          fi
          
          TOTAL_LINES=$(jq -r '.total.lines.pct // 0' "$COVERAGE_FILE")
          TOTAL_STATEMENTS=$(jq -r '.total.statements.pct // 0' "$COVERAGE_FILE")
          TOTAL_FUNCTIONS=$(jq -r '.total.functions.pct // 0' "$COVERAGE_FILE")
          TOTAL_BRANCHES=$(jq -r '.total.branches.pct // 0' "$COVERAGE_FILE")
          
          echo "total_lines=${TOTAL_LINES}" >> $GITHUB_OUTPUT
          echo "total_statements=${TOTAL_STATEMENTS}" >> $GITHUB_OUTPUT
          echo "total_functions=${TOTAL_FUNCTIONS}" >> $GITHUB_OUTPUT
          echo "total_branches=${TOTAL_BRANCHES}" >> $GITHUB_OUTPUT
          
          # Component-level coverage not available in json-summary format
          # Jest threshold enforcement handles component-level requirements
          echo "✅ Global coverage extracted - component coverage enforced by Jest thresholds"
          
          echo "✅ Coverage summary extracted successfully"
        else
          echo "❌ Coverage summary file not found"
          echo "total_lines=0" >> $GITHUB_OUTPUT
          echo "total_statements=0" >> $GITHUB_OUTPUT
          echo "total_functions=0" >> $GITHUB_OUTPUT
          echo "total_branches=0" >> $GITHUB_OUTPUT
        fi
      
    - name: Upload Coverage Reports
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report
        path: coverage/
        
    - name: Add Coverage Comment to PR
      if: github.event_name == 'pull_request'
      uses: marocchino/sticky-pull-request-comment@v2
      with:
        recreate: true
        header: "test-coverage"
        message: |
          # Test Coverage Report

          | Metric | Current | Threshold | Status |
          | ------ | ------- | --------- | ------ |
          | **Line Coverage** | ${{ steps.read-coverage.outputs.total_lines }}% | ≥36% | ${{ steps.read-coverage.outputs.total_lines < 36 && '❌ Below' || '✅ Pass' }} |
          | **Statement Coverage** | ${{ steps.read-coverage.outputs.total_statements }}% | ≥35% | ${{ steps.read-coverage.outputs.total_statements < 35 && '❌ Below' || '✅ Pass' }} |
          | **Function Coverage** | ${{ steps.read-coverage.outputs.total_functions }}% | ≥32% | ${{ steps.read-coverage.outputs.total_functions < 32 && '❌ Below' || '✅ Pass' }} |
          | **Branch Coverage** | ${{ steps.read-coverage.outputs.total_branches }}% | ≥24% | ${{ steps.read-coverage.outputs.total_branches < 24 && '❌ Below' || '✅ Pass' }} |

          **Coverage Status**: Based on current realistic thresholds set to prevent regression.

          ### About These Thresholds
          - These are **realistic thresholds** set to prevent regression, not aspirational targets
          - **Component-level coverage** is enforced by Jest during test execution
          - **Global coverage** shown above represents the overall project coverage
          - Jest will fail the build if any component-specific thresholds are not met

          > 📊 **Component Coverage**: Enforced by Jest at build time
          > - **Atoms**: Lines ≥75%, Statements ≥75%, Functions ≥83%, Branches ≥50%  
          > - **Molecules**: Lines ≥43%, Statements ≥42%, Functions ≥41%, Branches ≥43%
          > - **Organisms**: Lines ≥25%, Statements ≥24%, Functions ≥25%, Branches ≥31%
      
    - name: Cache build output
      uses: actions/cache@v4
      with:
        path: |
          .next
          storybook-static
        key: ${{ runner.os }}-build-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-build-

    - name: Install Playwright Browsers
      run: npx playwright install --with-deps
      # This installs all browsers (Chromium, Firefox, WebKit) required for E2E tests

    - name: Run E2E Tests
      run: |
        # Set CI to true explicitly to enable CI-specific settings in playwright.config.ts
        # This includes longer timeouts, retries, and disabling "only" tests
        CI=true npm run test:e2e
      # This step will automatically fail if any E2E tests fail
      env:
        CI: true
        E2E_MOCK_AUTH_ENABLED: true

    - name: Upload E2E Test Results
      if: always() # Run even if tests fail
      uses: actions/upload-artifact@v4
      with:
        name: playwright-report
        path: playwright-report/
        retention-days: 7

    - name: Upload E2E Test Artifacts
      if: always() # Run even if tests fail
      uses: actions/upload-artifact@v4
      with:
        name: e2e-artifacts
        path: |
          test-results/
          screenshots/
        retention-days: 3
        if-no-files-found: ignore

    - name: Install Storybook Test Runner
      run: npm install @storybook/test-runner --no-save

    - name: Ensure report directories exist
      run: |
        mkdir -p test-results
        mkdir -p lighthouse-results
        
        # Create placeholder reports if they don't exist
        if [ ! -f "test-results/a11y-summary.md" ]; then
          echo "# Accessibility Test Summary\n\nStorybook accessibility test results." > test-results/a11y-summary.md
        fi
        
        if [ ! -f "lighthouse-results/performance-summary.md" ]; then
          echo "# Performance Test Summary\n\nLighthouse performance test results." > lighthouse-results/performance-summary.md
        fi
    
    - name: Run Accessibility Tests
      env:
        CI: 'true'
        A11Y_FAILING_IMPACTS: 'critical,serious'
        GEMINI_API_KEY: 'test-api-key-for-testing-only'
      run: |
        # Use enhanced CI runner for better reliability and error reporting
        node scripts/storybook/run-a11y-tests-ci.js

    - name: Upload Accessibility Test Results
      if: always() # Run even if accessibility tests fail
      uses: actions/upload-artifact@v4
      with:
        name: accessibility-results
        path: |
          test-results/
        retention-days: 7

    - name: Add Accessibility Report to PR
      if: github.event_name == 'pull_request' && always()
      uses: marocchino/sticky-pull-request-comment@v2
      with:
        recreate: true
        path: test-results/a11y-summary.md
        header: "accessibility-report"

    # Performance Testing with Lighthouse CI
    - name: Install Lighthouse CI
      run: npm install -g @lhci/cli puppeteer

    - name: Run Lighthouse CI
      run: |
        # Start the server in the background
        npm run build
        npx http-server ./.next -p 3000 --silent &
        SERVER_PID=$!

        # Wait for server to start
        sleep 5

        # Run Lighthouse CI
        lhci autorun --config=./.lighthouserc.js

        # Generate the performance summary for PR comments
        node scripts/lighthouse/generate-summary.js

        # Kill the server
        kill $SERVER_PID
      env:
        LHCI_BUILD_CONTEXT__GITHUB_REPO_OWNER: ${{ github.repository_owner }}
        LHCI_BUILD_CONTEXT__GITHUB_REPO_NAME: ${{ github.repository }}
        LHCI_BUILD_CONTEXT__GITHUB_RUN_ID: ${{ github.run_id }}
        LHCI_BUILD_CONTEXT__CURRENT_HASH: ${{ github.sha }}
        LHCI_BUILD_CONTEXT__COMMIT_TIME: ${{ github.event.head_commit.timestamp }}
        LHCI_TOKEN: ${{ secrets.LHCI_TOKEN }}

    - name: Upload Lighthouse Reports
      if: always() # Run even if Lighthouse tests fail
      uses: actions/upload-artifact@v4
      with:
        name: lighthouse-results
        path: ./lighthouse-results
        retention-days: 7

    - name: Add Performance Report to PR
      if: github.event_name == 'pull_request' && always()
      uses: marocchino/sticky-pull-request-comment@v2
      with:
        recreate: true
        path: lighthouse-results/performance-summary.md
        header: "performance-report"

  # Add additional jobs as needed, such as:
  # - Deployment jobs
  # - Visual regression tests
  # - Integration tests